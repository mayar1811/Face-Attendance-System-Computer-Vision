{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8XO0e_x9NMf",
        "outputId": "27cf0fa0-6fbd-4c06-d009-46d1566de5b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-facenet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2qbkdejBr-c",
        "outputId": "f1bf4b1c-696f-4beb-c6a4-79c233cb8256"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-facenet\n",
            "  Downloading keras-facenet-0.3.2.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mtcnn (from keras-facenet)\n",
            "  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from mtcnn->keras-facenet) (1.5.0)\n",
            "Collecting lz4>=4.3.3 (from mtcnn->keras-facenet)\n",
            "  Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Downloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: keras-facenet\n",
            "  Building wheel for keras-facenet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-facenet: filename=keras_facenet-0.3.2-py3-none-any.whl size=10367 sha256=1fad45be948701f2c47e7b19767559b50def3f61679930e599d9d94052add2ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/99/94/dd/cb1a65a7440ba6d508bd24346c15af0b1d24ff8b1cdb1c9959\n",
            "Successfully built keras-facenet\n",
            "Installing collected packages: lz4, mtcnn, keras-facenet\n",
            "Successfully installed keras-facenet-0.3.2 lz4-4.4.4 mtcnn-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb1Yk6saFblW",
        "outputId": "84247498-09e8-41f2-b0be-299291fcd5e4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJfpxccQFdKE",
        "outputId": "a7d8507f-222b-439b-f0dc-7c0bec3dce19"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import csv\n",
        "import pickle\n",
        "import numpy as np\n",
        "from keras_facenet import FaceNet\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from datetime import datetime\n",
        "\n",
        "# Load pretrained FaceNet model (MTCNN + embeddings)\n",
        "embedder = FaceNet()\n",
        "print(\"✅ FaceNet model loaded\")\n",
        "\n",
        "# Load stored FaceNet embeddings and label encoder\n",
        "data = np.load(\"/content/embeddings_dataset.npz\")\n",
        "stored_embeddings = data['arr_0']  # normalized embeddings\n",
        "stored_labels = data['arr_1']      # integer-encoded labels\n",
        "\n",
        "with open(\"/content/label_encoder.pkl\", \"rb\") as f:\n",
        "    label_encoder = pickle.load(f)\n",
        "\n",
        "test_dir = \"/content/drive/MyDrive/testing_dataset\"\n",
        "output_csv = \"/content/facenet_test_results_2.csv\"\n",
        "vis_output_dir = \"/content/facenet_prediction_visuals\"\n",
        "os.makedirs(vis_output_dir, exist_ok=True)\n",
        "\n",
        "# Open CSV file for one-entry-per-image results\n",
        "with open(output_csv, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\n",
        "        'Image',\n",
        "        'Num_Faces',\n",
        "        'Predictions',\n",
        "        'Similarities',\n",
        "        'Match_Statuses',\n",
        "        'Bounding_Boxes'\n",
        "    ])\n",
        "\n",
        "    for img_name in os.listdir(test_dir):\n",
        "        img_path = os.path.join(test_dir, img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            print(f\"[WARN] Skipping unreadable image: {img_name}\")\n",
        "            continue\n",
        "\n",
        "        rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        results = embedder.extract(rgb_img, threshold=0.95)\n",
        "\n",
        "        if not results:\n",
        "            writer.writerow([img_name, 0, \"No face detected\", \"\", \"\", \"\"])\n",
        "            continue\n",
        "\n",
        "        predictions = []\n",
        "        similarities = []\n",
        "        statuses = []\n",
        "        boxes = []\n",
        "\n",
        "        for face in results:\n",
        "            emb = face['embedding'].reshape(1, -1)\n",
        "            sims = cosine_similarity(emb, stored_embeddings)[0]\n",
        "            best_idx = np.argmax(sims)\n",
        "            similarity = sims[best_idx]\n",
        "            predicted_name = label_encoder.inverse_transform([stored_labels[best_idx]])[0]\n",
        "\n",
        "            is_match = similarity > 0.75\n",
        "            label = f\"{predicted_name} ({similarity:.2f})\" if is_match else \"Unknown\"\n",
        "            status = \"Matched\" if is_match else \"Unknown\"\n",
        "\n",
        "            x, y, w, h = face['box']\n",
        "            x, y = abs(x), abs(y)\n",
        "            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "            cv2.putText(img, label, (x, y - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "            predictions.append(label)\n",
        "            similarities.append(f\"{similarity:.2f}\")\n",
        "            statuses.append(status)\n",
        "            boxes.append(f\"({x}, {y}, {w}, {h})\")\n",
        "\n",
        "        writer.writerow([\n",
        "            img_name,\n",
        "            len(results),\n",
        "            \"; \".join(predictions),\n",
        "            \"; \".join(similarities),\n",
        "            \"; \".join(statuses),\n",
        "            \"; \".join(boxes)\n",
        "        ])\n",
        "\n",
        "        output_path = os.path.join(vis_output_dir, f\"annotated_{img_name}\")\n",
        "        cv2.imwrite(output_path, img)\n",
        "\n",
        "print(f\"Inference complete. One-row-per-image results saved to: {output_csv}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOmMGzVDexAt",
        "outputId": "c6df9407-412e-4e5d-80f7-e04da51a47c1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ FaceNet model loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.3.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "✅ Inference complete. One-row-per-image results saved to: /content/facenet_test_results_2.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive('/content/facenet_prediction_visuals_2', 'zip', '/content/facenet_prediction_visuals_2')\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download('/content/facenet_prediction_visuals_2.zip')"
      ],
      "metadata": {
        "id": "yjmjSw9blrSs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}